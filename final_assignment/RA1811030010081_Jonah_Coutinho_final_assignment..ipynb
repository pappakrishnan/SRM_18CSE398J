{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers.core import Activation,Flatten,Dense,Dropout\n",
    "from keras import backend as k\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#to save images to background\n",
    "#matplotlib.use(\"Agg\")\n",
    "dataset_benign='C:/Users/benign'\n",
    "dataset_m_ductal='C:/Users/ductal_carcinoma'\n",
    "dataset_m_lobular='C:/Users/lobular_carcinoma'\n",
    "dataset_m_mucinous='C:/Users/mucinous_carcinoma'\n",
    "dataset_m_papillary='C:/Users/papillary_carcinoma'\n",
    "model_path=\"model.h5\"\n",
    "label_path=\"/\"\n",
    "plot_path=\"/\"\n",
    "HP_LR=1e-3\n",
    "HP_EPOCHS=100\n",
    "HP_BS=55\n",
    "HP_IMAGE_DIM=(96,96,3)\n",
    "data=[]\n",
    "classes=[]\n",
    "imagepaths_benign=sorted(list(paths.list_images(dataset_benign)))\n",
    "imagepaths_ductal=sorted(list(paths.list_images(dataset_m_ductal)))\n",
    "imagepaths_lobular=sorted(list(paths.list_images(dataset_m_lobular)))\n",
    "imagepaths_mucinous=sorted(list(paths.list_images(dataset_m_mucinous)))\n",
    "imagepaths_papillary=sorted(list(paths.list_images(dataset_m_papillary)))\n",
    "print(len(imagepaths_benign))\n",
    "print(len(imagepaths_ductal))\n",
    "print(len(imagepaths_lobular))\n",
    "print(len(imagepaths_papillary))\n",
    "print(len(imagepaths_mucinous))\n",
    "random.seed(42)\n",
    "imagepaths=imagepaths_ductal+imagepaths_lobular+imagepaths_mucinous+imagepaths_papillary+imagepaths_benign\n",
    "print(len(imagepaths))\n",
    "random.shuffle(imagepaths)\n",
    "print()\n",
    "#print(imagepaths[1])\n",
    "print(len(imagepaths))\n",
    "classes=[]\n",
    "for imgpath in imagepaths:\n",
    "    try:\n",
    "        image=cv2.imread(imgpath)\n",
    "        image=cv2.resize(image,(96,96))\n",
    "        image_array=img_to_array(image)\n",
    "        data.append(image_array)\n",
    "        label=imgpath.split('/')[-1]\n",
    "        temp=label.split(os.path.sep)[-2]\n",
    "        print(temp)\n",
    "        #print(label)\n",
    "        #if label in ['ductal_carcinoma','papillary_carcinoma','lobular_carcinoma','mucinous_carcinoma']:\n",
    "        #  label='malignant'\n",
    "        #print(label)\n",
    "        classes.append(temp)    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "print(classes)\n",
    "#normalization\n",
    "data=np.array(data,dtype=float)\n",
    "data=data/255.0\n",
    "labels=np.array(classes)\n",
    "lb=LabelBinarizer()\n",
    "labels=lb.fit_transform(labels)\n",
    "print(len(data))\n",
    "print(classes[0])\n",
    "print(labels[0])\n",
    "print(classes[6])\n",
    "print(labels[6])\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data,labels,test_size=0.2,random_state=42)\n",
    "aug=ImageDataGenerator(rotation_range=0.25,width_shift_range=0.25,height_shift_range=0.1,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\n",
    "#model=tinyVGG.build(height=96,width=96,depth=3,classes=len(lb.classes_))\n",
    "model=Sequential()\n",
    "input_shape=(96,96,3)\n",
    "channel_dim=-1\n",
    "\n",
    "#large patterns in smaller images\n",
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "#model.add(Dropout(0.25))\n",
    "#increase filter and reduce pool size to find better and finer patterns\n",
    "model.add(Conv2D(64,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(Conv2D(64,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "\"\"\"\n",
    "#Deleted layers \n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(Conv2D(256,(3,3),padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channel_dim))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\"\"\"\n",
    "model.add(Flatten())#converts into a single dimensional array\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    " \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "mc = ModelCheckpoint('weights.best.keras', monitor='val_acc', save_best_only=True)\n",
    "aug=ImageDataGenerator(rotation_range=0.25,width_shift_range=0.25,height_shift_range=0.1,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\n",
    "opt=Adam(lr=HP_LR,decay=HP_LR/HP_EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=['accuracy'])\n",
    "history=model.fit_generator(aug.flow(xtrain,ytrain,batch_size=HP_BS),validation_data=(xtest,ytest),steps_per_epoch=len(xtrain)//HP_BS,epochs=HP_EPOCHS)\n",
    "model.save('mymodcat2.h5')\n",
    "\n",
    "#loss = history.history['loss']\n",
    "#accuracy = history.history['acc']\n",
    "gt=[]\n",
    "pred=[]\n",
    "predictions=model.predict(xtest)\n",
    "\n",
    "for i in range(len(xtest)):\n",
    "    pred.append(np.argmax(predictions[i]))\n",
    "   \n",
    "print(pred)\n",
    "for i in range(len(xtest)):\n",
    "    for j in range(5):\n",
    "        if ytest[i][j]==1:\n",
    "            gt.append(j)\n",
    "           \n",
    "           \n",
    "     \n",
    "for i in range(100):\n",
    "    print(np.argmax(predictions[i])+1)\n",
    "    print(ytest[i])\n",
    "print(gt)\n",
    "\n",
    "print(len(xtest))\n",
    "count=0\n",
    "for i in range(len(xtest)):\n",
    "    if pred[i]!=gt[i]:\n",
    "        count+=1\n",
    "print(count)\n",
    "print(confusion_matrix(pred,gt))\n",
    "print(\"testing accuracy=\",1-(count/len(xtest)))\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(5):\n",
    "        if ytrain[i][j]==1:\n",
    "             x.append(j)\n",
    "for i in range(len(predictions)):\n",
    "    y.append(np.argmax(predictions[i])+1)\n",
    "   \n",
    "   \n",
    "         \n",
    "plt.plot(y,x)\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
