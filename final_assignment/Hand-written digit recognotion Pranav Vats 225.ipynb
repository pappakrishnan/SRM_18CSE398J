{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(x_train[200], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(x_train[345], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mishv\\OneDrive\\Documents\\Conda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 35s 578us/step - loss: 0.2323 - accuracy: 0.9285 - val_loss: 0.0528 - val_accuracy: 0.9832\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0654 - accuracy: 0.9799 - val_loss: 0.0443 - val_accuracy: 0.9860\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 33s 551us/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.0454 - val_accuracy: 0.9850\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0433 - val_accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 33s 549us/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.0290 - val_accuracy: 0.9910\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0267 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 33s 556us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0265 - val_accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0291 - val_accuracy: 0.9915\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0286 - val_accuracy: 0.9919\n",
      "The model has been succefully trained.\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "print(\"The model has been succefully trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained weights have been saved.\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist.h5')\n",
    "print('The trained weights have been saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 172us/step\n",
      "Test loss: 0.02858012642698086\n",
      "Test accuracy: 0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number predicted is :  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print('The number predicted is : ', pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights loaded\n",
      "6\n",
      "2\n",
      "0\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "import os\n",
    "import cv2\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('mnist.h5')\n",
    "print('Trained weights loaded')\n",
    "\n",
    "def get_handle():\n",
    "    toplist = []\n",
    "    windows_list = []\n",
    "    canvas = 0\n",
    "    def enum_win(hwnd, result):\n",
    "        win_text = win32gui.GetWindowText(hwnd)\n",
    "        #print(hwnd, win_text)\n",
    "        windows_list.append((hwnd, win_text))\n",
    "    win32gui.EnumWindows(enum_win, toplist)\n",
    "    for (hwnd, win_text) in windows_list:\n",
    "        if 'tk' == win_text:\n",
    "            canvas = hwnd\n",
    "    return canvas\n",
    "\n",
    "def preprocessing_image():\n",
    "    \"\"\"function to preprocess the image to\"\"\"\n",
    "    image = cv2.imread('test.jpg')\n",
    "    #print(type(image))\n",
    "    grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV)\n",
    "    # cv2.imshow('binarized image', thresh)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # print(type(contours[0]))\n",
    "    # print(len(contours[0]))\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n",
    "    #cv2.imshow('Contours', image) \n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)        \n",
    "        # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "        # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "        digit = thresh[y:y+h, x:x+w]        \n",
    "        # Resizing that digit to (18, 18)\n",
    "        resized_digit = cv2.resize(digit, (18,18))        \n",
    "        # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "        padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)        \n",
    "        # Adding the preprocessed digit to the list of preprocessed digits\n",
    "        preprocessed_digit = (padded_digit)\n",
    "    return preprocessed_digit\n",
    "\n",
    "def predict_digit(img):\n",
    "    \"\"\"function to predict the digit. \n",
    "    Argument of function is PIL Image\"\"\"\n",
    "    img.save('test.jpg')\n",
    "    preprocessed_image = preprocessing_image()\n",
    "    # print(type(preprocessed_image))\n",
    "    # print(preprocessed_image.shape)\n",
    "    img = preprocessed_image.reshape(1, 28, 28, 1)\n",
    "    img = img/255.0\n",
    "    #predicting the digit\n",
    "    result = model.predict([img])[0]\n",
    "    os.remove('test.jpg')\n",
    "    return np.argmax(result), max(result)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Draw\", font=(\"Calibri\", 40))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command = self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        hwnd = get_handle()\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        x1, y1, x2, y2 = rect\n",
    "        # print(x1,x2, y1,y2)\n",
    "        im = ImageGrab.grab((x1+40, y1+40, x2+100, y2+100))\n",
    "        digit, acc = predict_digit(im)\n",
    "        print(digit)\n",
    "        \n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
